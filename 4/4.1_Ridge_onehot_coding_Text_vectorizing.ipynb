{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Замените все, кроме букв и цифр, на пробелы\n",
    "# salary_train.zip:\n",
    "# https://d3c33hcgiwev3.cloudfront.net/_2a5a306cfe8235d3e65bddf5a5be6d0a_salary-train.zip?Expires=1628812800&Signature=WkxA4fTOy64jfadiljDngGAtdrF8I1cCF4u4FZZHXpAvfg~B~9sklzPYPSEIvcTCjBEzNgah7UGSoYRgAggwEZIPAP0S1NTKfbD5YfsOUoZ9QKWZkthNKA6pSy1u56wnbnvYDLf-amZW5LGL06ZUh7B00jl3VsK-w-Oh4fvYZM4_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A\n",
    "\n",
    "salary_train_df = pd.read_csv('salary-train.csv').replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "salary_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Замените все, кроме букв и цифр, на пробелы \n",
    "salary_test_df = pd.read_csv('salary-test-mini.csv').replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "salary_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замените пропуски в столбцах LocationNormalized и ContractTime на специальную строку 'nan'\n",
    "salary_train_df['LocationNormalized'].fillna('nan', inplace=True)\n",
    "salary_train_df['ContractTime'].fillna('nan', inplace=True)\n",
    "\n",
    "salary_test_df['LocationNormalized'].fillna('nan', inplace=True)\n",
    "salary_test_df['ContractTime'].fillna('nan', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведите тексты к нижнему регистру (text.lower())\n",
    "for col in salary_train_df.columns.drop(['SalaryNormalized']):\n",
    "    salary_train_df[col] = salary_train_df[col].str.lower()\n",
    "    salary_test_df[col] = salary_test_df[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Примените TfidfVectorizer для преобразования текстов в векторы признаков. \n",
    "# Оставьте только те слова, которые встречаются хотя бы в 5 объектах \n",
    "# (параметр min_df у TfidfVectorizer).\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 5)\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(salary_train_df['FullDescription'])\n",
    "X_test_vec = vectorizer.transform(salary_test_df['FullDescription']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Примените DictVectorizer для получения \n",
    "# one-hot-кодирования признаков LocationNormalized и ContractTime\n",
    "\n",
    "encoder = DictVectorizer(sparse = False)\n",
    "\n",
    "X_train_categ = encoder.fit_transform(salary_train_df[['LocationNormalized', 'ContractTime']].to_dict('records'))\n",
    "X_test_categ = encoder.transform(salary_test_df[['LocationNormalized', 'ContractTime']].to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объедините все полученные признаки в одну матрицу \"объекты-признаки\". \n",
    "# Обратите внимание, что матрицы для текстов \n",
    "# и категориальных признаков являются разреженными. \n",
    "# Для объединения их столбцов нужно воспользоваться функцией scipy.sparse.hstack\n",
    "\n",
    "X_train = hstack([X_train_vec, X_train_categ])\n",
    "X_test = hstack([X_test_vec, X_test_categ])\n",
    "# целевая переменная\n",
    "y_train = salary_train_df['SalaryNormalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, random_state=241)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучите гребневую регрессию с параметрами alpha=1 и random_state=241\n",
    "\n",
    "ridge = Ridge(alpha = 1, random_state = 241)\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56576.86\n",
      "37136.3\n"
     ]
    }
   ],
   "source": [
    "# прогнозы для двух примеров из файла salary-test-mini.csv\n",
    "\n",
    "pred = ridge.predict(X_test)\n",
    "for p in pred:\n",
    "    print(round(p, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
